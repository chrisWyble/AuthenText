{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80335498-515e-4065-bce5-feef133b1e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from io import StringIO\n",
    "from flask import Flask, request, jsonify\n",
    "from dotenv import load_dotenv\n",
    "from binoculars import Binoculars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d3e2676-6290-48eb-9c1e-2837c32cb4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/softwares/python3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "\n",
      "WARNING: You are currently loading Falcon using legacy code contained in the model repository. Falcon has now been fully ported into the Hugging Face transformers library. For the most up-to-date and high-performance version of the Falcon model code, please update to the latest version of transformers and then load the model without the trust_remote_code=True argument.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e77ca67e368f4ea58ed24152179fc43e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/softwares/python3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82e54a793a89494cba131b9966d7577d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of FalconForCausalLM were not initialized from the model checkpoint at vilsonrodrigues/falcon-7b-instruct-sharded and are newly initialized: ['lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using pad_token, but it is not set yet.\n"
     ]
    }
   ],
   "source": [
    "binoculars = Binoculars()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "533ea32f-c8bd-4697-85b8-86e44ddaf0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(f\"../credentials.env\")\n",
    "s3 = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id=os.getenv('aws_access_key_id'),\n",
    "    aws_secret_access_key=os.getenv('aws_secret_access_key')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71da8796-35a3-465a-86b1-3e314a3d3de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://172.31.41.150:5000\n",
      "Press CTRL+C to quit\n",
      "54.198.173.193 - - [08/Aug/2024 22:50:44] \"GET /view_archive HTTP/1.1\" 200 -\n",
      "54.198.173.193 - - [08/Aug/2024 22:51:43] \"POST /predict HTTP/1.1\" 200 -\n",
      "54.198.173.193 - - [08/Aug/2024 22:51:49] \"PUT /archive HTTP/1.1\" 200 -\n",
      "54.198.173.193 - - [08/Aug/2024 22:51:55] \"GET /view_archive HTTP/1.1\" 200 -\n",
      "198.235.24.24 - - [08/Aug/2024 23:28:11] \"GET / HTTP/1.0\" 404 -\n",
      "54.198.173.193 - - [08/Aug/2024 23:36:52] \"GET /view_archive HTTP/1.1\" 200 -\n",
      "54.198.173.193 - - [08/Aug/2024 23:37:18] \"POST /predict HTTP/1.1\" 200 -\n",
      "54.198.173.193 - - [08/Aug/2024 23:37:27] \"PUT /archive HTTP/1.1\" 200 -\n",
      "54.198.173.193 - - [08/Aug/2024 23:37:34] \"GET /view_archive HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/predict', methods=['POST','GET'])\n",
    "def predict():\n",
    "    # Run binocular model on input files\n",
    "    data = request.get_json()\n",
    "    response = data.get('text', 'No text provided')  # Retrieve the 'text' field from the JSON payload\n",
    "    if response != 'No text provided':\n",
    "        score_vec = binoculars.compute_score(response)\n",
    "    res_lst = [] \n",
    "    \n",
    "    # Filter on threshold discovered in our datasets\n",
    "    for s in score_vec: \n",
    "        res_lst.append('Potential MGT Detected' if s < 0.8676735347069413 else 'No MGT Detected')\n",
    "    \n",
    "    return jsonify({'response': res_lst})\n",
    "\n",
    "@app.route('/archive', methods=['PUT'])\n",
    "def archive():\n",
    "    # Store the summary of the binoculars model on file(s)\n",
    "    bucket_name = 'authen-text-archive'\n",
    "    data = request.get_json()\n",
    "    paths, mgt_status, text = data.get('filenames', ''), data.get('mgt_status'), data.get('text')\n",
    "    \n",
    "    for idx, path in enumerate(paths):\n",
    "        data_dict = {'text': text[idx], 'mgt_status': mgt_status[idx]}\n",
    "        data_string = json.dumps(data_dict , default=str)\n",
    "        \n",
    "        # Upload JSON String to an S3 Object\n",
    "        s3.put_object(\n",
    "            Bucket=bucket_name, \n",
    "            Key=f'{path}.json',\n",
    "            Body=data_string\n",
    "        )\n",
    "\n",
    "    status = 'Successfully Stored in Archive'\n",
    "    return jsonify({'response': status})\n",
    "    \n",
    "@app.route('/view_archive', methods=['GET'])\n",
    "def view_archive():\n",
    "    \n",
    "    # Display the context of the archive bucket to user\n",
    "    try:\n",
    "        # Initialize a session using your AWS credentials\n",
    "        s3_client = boto3.client(\n",
    "            's3',\n",
    "            aws_access_key_id=os.getenv('aws_access_key_id'),\n",
    "            aws_secret_access_key=os.getenv('aws_secret_access_key')\n",
    "        )\n",
    "\n",
    "        s3_resource = boto3.resource(\n",
    "                        's3',\n",
    "                        aws_access_key_id=os.getenv('aws_access_key_id'),\n",
    "                        aws_secret_access_key=os.getenv('aws_secret_access_key')\n",
    "                    )\n",
    "        \n",
    "        bucket_name = 'authen-text-archive'\n",
    "    \n",
    "        # Listing out the objects in a bucket\n",
    "        essay_trainning_bucket = s3_resource.Bucket(name = bucket_name)\n",
    "        keys = [object.key for object in essay_trainning_bucket.objects.all()]\n",
    "\n",
    "        series_lst = []\n",
    "\n",
    "        for file_key in keys:\n",
    "            # Download the file from S3 to a string buffer\n",
    "            obj = s3_client.get_object(Bucket=bucket_name, Key=file_key)\n",
    "            data = obj['Body'].read().decode('utf-8')\n",
    "            \n",
    "            \n",
    "            # Use StringIO to convert the string data to a pandas-readable buffer\n",
    "            data_buffer = StringIO(data)\n",
    "            \n",
    "            # Read the data into a pandas DataFrame\n",
    "            series = pd.read_json(data_buffer, typ='series')\n",
    "            \n",
    "            series['text'] = series['text'][:60] if len(series['text']) > 60 else series['text']\n",
    "            series['mgt_status'] = 'Yes' if series['mgt_status'] else 'No'\n",
    "            series['Document'] = file_key.split('.')[0].split('__')[1]\n",
    "            series['Student ID'] = file_key.split('/')[0]\n",
    "\n",
    "            series_lst.append(series)\n",
    "        \n",
    "        df = pd.DataFrame(series_lst)\n",
    "        df = df[['Student ID', 'Document', 'text', 'mgt_status']]\n",
    "        df.rename(columns={'mgt_status':'Potential MGT Detected'}, inplace=True)\n",
    "        \n",
    "        return jsonify({'response': df.to_dict()})\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f02cfa-d265-4e90-bced-d8962fa61145",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
